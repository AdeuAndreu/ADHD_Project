{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "from sklearn import svm,tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "#import supervisedLearning_commons\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oneHotEncoding(train, numeric_cols):\n",
    "    # receives the clean tain and test data\n",
    "    # in: train and test numpy matrix\n",
    "    x_num_train = train[numeric_cols].as_matrix()\n",
    "    #x_num_test = test[numeric_cols].as_matrix()\n",
    "    cat_train = train.drop(numeric_cols, axis=1)\n",
    "    #cat_test = test.drop(numeric_cols, axis=1)\n",
    "    x_cat_train = cat_train.T.to_dict().values()\n",
    "    #x_cat_test = cat_test.T.to_dict().values()\n",
    "    # 5.1 vectorize\n",
    "    vectorizer = DV(sparse=False)\n",
    "    vec_x_cat_train = vectorizer.fit_transform(x_cat_train)\n",
    "    #vec_x_cat_test = vectorizer.transform(x_cat_test)\n",
    "    # complete x\n",
    "    x_train = np.hstack((x_num_train, vec_x_cat_train))\n",
    "    #x_test = np.hstack((x_num_test, vec_x_cat_test))\n",
    "    return x_train\n",
    "\n",
    "def randomization_train_2_twoSet(x_train,y_train,PRC):\n",
    "    #Alternative:\n",
    "    #from sklearn.cross_validation import train_test_split\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=PRC)\n",
    "    perm = np.random.permutation(x_train.shape[0])\n",
    "    split_point = int(np.ceil(y_train.shape[0]*PRC))\n",
    "\n",
    "    X_train = x_train[perm[:split_point].ravel(),:]\n",
    "    Y_train = y_train[perm[:split_point].ravel()]\n",
    "\n",
    "    X_test = x_train[perm[split_point:].ravel(),:]\n",
    "    Y_test = y_train[perm[split_point:].ravel()]\n",
    "\n",
    "    return (X_train, Y_train, X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1.Read DAta\n",
    "path_data = '/Users/mirta/BIGDATA/PROJECT/ADHD_Project-master/SupervisedLearning/data_for_learning/'\n",
    "train = pd.read_csv(path_data+'SupervisedLearningDataSet_Lunes11.csv')\n",
    "\n",
    "train = train[train.experiment == 'B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>BPR_C3</th>\n",
       "      <th>BPR_C4</th>\n",
       "      <th>BPR_Cz</th>\n",
       "      <th>BPR_F3</th>\n",
       "      <th>BPR_F4</th>\n",
       "      <th>BPR_Fp1</th>\n",
       "      <th>BPR_Fp2</th>\n",
       "      <th>BPR_Fz</th>\n",
       "      <th>C3_(Alpha)</th>\n",
       "      <th>...</th>\n",
       "      <th>Fz_(Beta_Global)</th>\n",
       "      <th>Fz_(Gamma)</th>\n",
       "      <th>Fz_(Theta)</th>\n",
       "      <th>Fz_(Theta2+Alpha1)</th>\n",
       "      <th>experiment</th>\n",
       "      <th>norm64comp_PCA_x</th>\n",
       "      <th>norm64comp_PCA_y</th>\n",
       "      <th>norm64comp_PCA_z</th>\n",
       "      <th>patientName</th>\n",
       "      <th>Best_Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16.554281</td>\n",
       "      <td>6.789196</td>\n",
       "      <td>20.152363</td>\n",
       "      <td>9.927679</td>\n",
       "      <td>13.822268</td>\n",
       "      <td>9.465081</td>\n",
       "      <td>10.287247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.781468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B</td>\n",
       "      <td>-0.530249</td>\n",
       "      <td>-3.289800</td>\n",
       "      <td>1.370542</td>\n",
       "      <td>S100_B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19.213702</td>\n",
       "      <td>24.777468</td>\n",
       "      <td>25.793031</td>\n",
       "      <td>14.806750</td>\n",
       "      <td>15.325136</td>\n",
       "      <td>10.182399</td>\n",
       "      <td>12.103343</td>\n",
       "      <td>15.733937</td>\n",
       "      <td>1.289775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457749</td>\n",
       "      <td>0.159458</td>\n",
       "      <td>4.923992</td>\n",
       "      <td>2.601960</td>\n",
       "      <td>B</td>\n",
       "      <td>1.905199</td>\n",
       "      <td>-6.992737</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>S101_B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>13.408050</td>\n",
       "      <td>21.453597</td>\n",
       "      <td>23.529602</td>\n",
       "      <td>11.064114</td>\n",
       "      <td>14.225991</td>\n",
       "      <td>11.041689</td>\n",
       "      <td>10.486719</td>\n",
       "      <td>16.418801</td>\n",
       "      <td>2.351850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373856</td>\n",
       "      <td>0.211185</td>\n",
       "      <td>3.869544</td>\n",
       "      <td>3.144678</td>\n",
       "      <td>B</td>\n",
       "      <td>1.225918</td>\n",
       "      <td>-0.075368</td>\n",
       "      <td>1.469183</td>\n",
       "      <td>S102_B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>22.739612</td>\n",
       "      <td>15.554675</td>\n",
       "      <td>23.285264</td>\n",
       "      <td>23.821072</td>\n",
       "      <td>12.947290</td>\n",
       "      <td>13.554576</td>\n",
       "      <td>13.480529</td>\n",
       "      <td>13.433892</td>\n",
       "      <td>1.937868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515978</td>\n",
       "      <td>0.235098</td>\n",
       "      <td>3.978490</td>\n",
       "      <td>3.034652</td>\n",
       "      <td>B</td>\n",
       "      <td>1.211349</td>\n",
       "      <td>-3.472660</td>\n",
       "      <td>-0.778755</td>\n",
       "      <td>S103_B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>20.104660</td>\n",
       "      <td>16.025724</td>\n",
       "      <td>25.382202</td>\n",
       "      <td>18.209489</td>\n",
       "      <td>16.298085</td>\n",
       "      <td>15.717418</td>\n",
       "      <td>13.721229</td>\n",
       "      <td>20.871859</td>\n",
       "      <td>1.616361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462846</td>\n",
       "      <td>0.193141</td>\n",
       "      <td>4.436727</td>\n",
       "      <td>3.184091</td>\n",
       "      <td>B</td>\n",
       "      <td>0.718661</td>\n",
       "      <td>-4.954779</td>\n",
       "      <td>-1.124442</td>\n",
       "      <td>S104_B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0     BPR_C3     BPR_C4     BPR_Cz     BPR_F3     BPR_F4  \\\n",
       "0            0  16.554281   6.789196  20.152363   9.927679  13.822268   \n",
       "2            2  19.213702  24.777468  25.793031  14.806750  15.325136   \n",
       "5            5  13.408050  21.453597  23.529602  11.064114  14.225991   \n",
       "7            7  22.739612  15.554675  23.285264  23.821072  12.947290   \n",
       "10          10  20.104660  16.025724  25.382202  18.209489  16.298085   \n",
       "\n",
       "      BPR_Fp1    BPR_Fp2     BPR_Fz  C3_(Alpha)      ...       \\\n",
       "0    9.465081  10.287247   0.000000    1.781468      ...        \n",
       "2   10.182399  12.103343  15.733937    1.289775      ...        \n",
       "5   11.041689  10.486719  16.418801    2.351850      ...        \n",
       "7   13.554576  13.480529  13.433892    1.937868      ...        \n",
       "10  15.717418  13.721229  20.871859    1.616361      ...        \n",
       "\n",
       "    Fz_(Beta_Global)  Fz_(Gamma)  Fz_(Theta)  Fz_(Theta2+Alpha1)  experiment  \\\n",
       "0           0.000000    0.000000    0.000000            0.000000           B   \n",
       "2           0.457749    0.159458    4.923992            2.601960           B   \n",
       "5           0.373856    0.211185    3.869544            3.144678           B   \n",
       "7           0.515978    0.235098    3.978490            3.034652           B   \n",
       "10          0.462846    0.193141    4.436727            3.184091           B   \n",
       "\n",
       "    norm64comp_PCA_x  norm64comp_PCA_y  norm64comp_PCA_z  patientName  \\\n",
       "0          -0.530249         -3.289800          1.370542       S100_B   \n",
       "2           1.905199         -6.992737          0.310811       S101_B   \n",
       "5           1.225918         -0.075368          1.469183       S102_B   \n",
       "7           1.211349         -3.472660         -0.778755       S103_B   \n",
       "10          0.718661         -4.954779         -1.124442       S104_B   \n",
       "\n",
       "    Best_Cluster  \n",
       "0              1  \n",
       "2              1  \n",
       "5              1  \n",
       "7              1  \n",
       "10             1  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y= train['Best_Cluster'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1\n",
      " 0 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 0 0 1 1 1\n",
      " 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################################################drop Cols\n",
    "numeric_cols=['norm64comp_PCA_x','norm64comp_PCA_y','Fp1_(Theta2+Alpha1)', 'Fp1_(Theta)', 'Fp1_(Alpha)',\n",
    "       'Fp1_(Beta_Global)', 'Fp1_(Beta_Alta)', 'Fp1_(Beta_Baja)',\n",
    "       'Fp1_(Gamma)', 'F3_(Theta2+Alpha1)', 'F3_(Theta)', 'F3_(Alpha)',\n",
    "       'F3_(Beta_Global)', 'F3_(Beta_Alta)', 'F3_(Beta_Baja)', 'F3_(Gamma)',\n",
    "       'C3_(Theta2+Alpha1)', 'C3_(Theta)', 'C3_(Alpha)', 'C3_(Beta_Global)',\n",
    "       'C3_(Beta_Alta)', 'C3_(Beta_Baja)', 'C3_(Gamma)', 'Fz_(Theta2+Alpha1)',\n",
    "       'Fz_(Theta)', 'Fz_(Alpha)', 'Fz_(Beta_Global)', 'Fz_(Beta_Alta)',\n",
    "       'Fz_(Beta_Baja)', 'Fz_(Gamma)', 'Cz_(Theta2+Alpha1)', 'Cz_(Theta)',\n",
    "       'Cz_(Alpha)', 'Cz_(Beta_Global)', 'Cz_(Beta_Alta)', 'Cz_(Beta_Baja)',\n",
    "       'Cz_(Gamma)', 'Fp2_(Theta2+Alpha1)', 'Fp2_(Theta)', 'Fp2_(Alpha)',\n",
    "       'Fp2_(Beta_Global)', 'Fp2_(Beta_Alta)', 'Fp2_(Beta_Baja)',\n",
    "       'Fp2_(Gamma)', 'F4_(Theta2+Alpha1)', 'F4_(Theta)', 'F4_(Alpha)',\n",
    "       'F4_(Beta_Global)', 'F4_(Beta_Alta)', 'F4_(Beta_Baja)', 'F4_(Gamma)',\n",
    "       'C4_(Theta2+Alpha1)', 'C4_(Theta)', 'C4_(Alpha)', 'C4_(Beta_Global)',\n",
    "       'C4_(Beta_Alta)', 'C4_(Beta_Baja)', 'C4_(Gamma)', 'BPR_Fp1', 'BPR_F3',\n",
    "       'BPR_C3', 'BPR_Fz', 'BPR_Cz', 'BPR_Fp2', 'BPR_F4', 'BPR_C4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = oneHotEncoding(train, numeric_cols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Separate train and test\n",
    "#PRC=0.3\n",
    "#X_train, y_train, X_test, y_test = randomization_train_2_twoSet(X,y,PRC=PRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18584\n",
      "92\n",
      "8080\n",
      "40\n",
      "26664\n",
      "132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "print X_train.size\n",
    "print y_train.size\n",
    "print X_test.size\n",
    "print y_test.size\n",
    "print X.size\n",
    "print y.size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM...\n"
     ]
    }
   ],
   "source": [
    "print (\"Training SVM...\")\n",
    "C = 20\n",
    "gamma = 1.31e-5\n",
    "shrinking = True\n",
    "probability = True\n",
    "verbose = True\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "svc = SVC( C = C, gamma = gamma, shrinking = shrinking, probability = probability, verbose = verbose,class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=20, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=1.31e-05, kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM results \n",
      "[0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1\n",
      " 1 1 1]\n",
      "True values\n",
      "[0 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1\n",
      " 1 1 1]\n",
      "Performance Evaluation\n"
     ]
    }
   ],
   "source": [
    "X_test = scaler.transform(X_test)\n",
    "my_prediction = svc.predict(X_test)\n",
    "\n",
    "print ('SVM results ')\n",
    "print my_prediction\n",
    "print ('True values')\n",
    "print y_test\n",
    "print ('Performance Evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM mean accuracy: 0.984848484848\n",
      "SVM mean F1-Score: 0.69696969697\n",
      "SVM mean precision: 0.69696969697\n",
      "SVM mean recall: 0.69696969697\n"
     ]
    }
   ],
   "source": [
    "# Using k-fold cross validations\n",
    "\n",
    "n_folds = y.size ## IF N_FOLDS is the size of the set, it is the same as LOO below\n",
    "kf=cross_validation.KFold(n=y.shape[0], n_folds=n_folds, shuffle=False, random_state=0)\n",
    "acc = np.zeros((n_folds,))\n",
    "f1 = np.zeros((n_folds,))\n",
    "precision = np.zeros((n_folds,))\n",
    "recall = np.zeros((n_folds,))\n",
    "i = 0\n",
    "X = X\n",
    "y = y\n",
    "yhat = y.copy()\n",
    "for train_index, test_index in kf:\n",
    "     \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "   \n",
    "    #dt = RandomForestClassifier(max_depth = max_depth, min_samples_split=min_samples_split, n_estimators=n_estimators, random_state = random_state,class_weight=class_weight)\n",
    "#    svc = SVC( C = C, gamma = gamma, shrinking = shrinking, probability = probability, verbose = verbose,class_weight='balanced')\n",
    "    svc = svm.SVC(C=C,kernel='rbf',class_weight='balanced')        \n",
    "    svc.fit(X_train,y_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    yhat[test_index] = svc.predict(X_test)\n",
    "    acc[i] = metrics.accuracy_score(yhat[test_index], y_test)\n",
    "    f1[i]  = metrics.f1_score(yhat[test_index], y_test)\n",
    "    precision[i] = metrics.precision_score(yhat[test_index], y_test)\n",
    "    recall[i] = metrics.recall_score(yhat[test_index], y_test)\n",
    "    i=i+1\n",
    "\n",
    "print ('SVM mean accuracy: '+ str(np.mean(acc)))\n",
    "print ('SVM mean F1-Score: '+ str(np.mean(f1)))\n",
    "print ('SVM mean precision: '+ str(np.mean(precision)))\n",
    "print ('SVM mean recall: '+ str(np.mean(recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM mean accuracy: 0.977272727273\n",
      "SVM mean F1-Score: 0.689393939394\n",
      "SVM mean precision: 0.689393939394\n",
      "SVM mean recall: 0.689393939394\n"
     ]
    }
   ],
   "source": [
    "n_loo=y.size\n",
    "loo=cross_validation.LeaveOneOut(n_loo)\n",
    "\n",
    "acc = np.zeros((n_loo,))\n",
    "f1 = np.zeros((n_loo,))\n",
    "precision = np.zeros((n_loo,))\n",
    "recall = np.zeros((n_loo,))\n",
    "i = 0\n",
    "X = X\n",
    "y = y\n",
    "yhat = y.copy()\n",
    "\n",
    "for train_index, test_index in loo:\n",
    "\n",
    "      \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    \n",
    "  \n",
    "    #dt = RandomForestClassifier(max_depth = max_depth, min_samples_split=min_samples_split, n_estimators=n_estimators, random_state = random_state,class_weight=class_weight)\n",
    "#    svc = SVC( C = C, gamma = gamma, shrinking = shrinking, probability = probability, verbose = verbose,class_weight='balanced')\n",
    "    svc = svm.SVC(C=1,kernel='rbf',class_weight='balanced')        \n",
    "    svc.fit(X_train,y_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    yhat[test_index] = svc.predict(X_test)\n",
    "\n",
    "    acc[i] = metrics.accuracy_score(yhat[test_index], y_test)\n",
    "    f1[i]  = metrics.f1_score(yhat[test_index], y_test)\n",
    "    precision[i] = metrics.precision_score(yhat[test_index], y_test)\n",
    "    recall[i] = metrics.recall_score(yhat[test_index], y_test)\n",
    "    i=i+1\n",
    "\n",
    "print ('SVM mean accuracy: '+ str(np.mean(acc)))\n",
    "print ('SVM mean F1-Score: '+ str(np.mean(f1)))\n",
    "print ('SVM mean precision: '+ str(np.mean(precision)))\n",
    "print ('SVM mean recall: '+ str(np.mean(recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM mean accuracy: 0.977272727273\n",
      "SVM mean F1-Score: 0.983585858586\n",
      "SVM mean precision: 0.99\n",
      "SVM mean recall: 0.977777777778\n",
      "SVM mean accuracy: 0.984848484848\n",
      "SVM mean F1-Score: 0.988505747126\n",
      "SVM mean precision: 0.988505747126\n",
      "SVM mean recall: 0.988505747126\n",
      "SVM mean accuracy: 0.984848484848\n",
      "SVM mean F1-Score: 0.988800398208\n",
      "SVM mean precision: 0.99\n",
      "SVM mean recall: 0.988095238095\n",
      "SVM mean accuracy: 0.9849002849\n",
      "SVM mean F1-Score: 0.988897224306\n",
      "SVM mean precision: 0.990909090909\n",
      "SVM mean recall: 0.9875\n",
      "SVM mean accuracy: 0.984848484848\n",
      "SVM mean F1-Score: 0.988776655443\n",
      "SVM mean precision: 0.990196078431\n",
      "SVM mean recall: 0.988095238095\n",
      "SVM mean accuracy: 0.984544695071\n",
      "SVM mean F1-Score: 0.987906273621\n",
      "SVM mean precision: 0.989795918367\n",
      "SVM mean recall: 0.987012987013\n",
      "SVM mean accuracy: 0.984834558824\n",
      "SVM mean F1-Score: 0.987212276215\n",
      "SVM mean precision: 0.989583333333\n",
      "SVM mean recall: 0.986111111111\n",
      "SVM mean accuracy: 0.984656084656\n",
      "SVM mean F1-Score: 0.987761674718\n",
      "SVM mean precision: 0.990740740741\n",
      "SVM mean recall: 0.986111111111\n",
      "SVM mean accuracy: 0.976923076923\n",
      "SVM mean F1-Score: 0.981162181472\n",
      "SVM mean precision: 0.978888888889\n",
      "SVM mean recall: 0.985714285714\n",
      "SVM mean accuracy: 0.969696969697\n",
      "SVM mean F1-Score: 0.97307078886\n",
      "SVM mean precision: 0.977922077922\n",
      "SVM mean recall: 0.974025974026\n",
      "SVM mean accuracy: 0.977272727273\n",
      "SVM mean F1-Score: 0.984681372549\n",
      "SVM mean precision: 0.980324074074\n",
      "SVM mean recall: 0.989583333333\n",
      "SVM mean accuracy: 0.976923076923\n",
      "SVM mean F1-Score: 0.981262327416\n",
      "SVM mean precision: 0.97619047619\n",
      "SVM mean recall: 0.987179487179\n",
      "SVM mean accuracy: 0.984920634921\n",
      "SVM mean F1-Score: 0.988011988012\n",
      "SVM mean precision: 0.989795918367\n",
      "SVM mean recall: 0.988095238095\n",
      "SVM mean accuracy: 0.975925925926\n",
      "SVM mean F1-Score: 0.979287379287\n",
      "SVM mean precision: 0.979365079365\n",
      "SVM mean recall: 0.983333333333\n",
      "SVM mean accuracy: 0.9765625\n",
      "SVM mean F1-Score: 0.980581918082\n",
      "SVM mean precision: 0.980654761905\n",
      "SVM mean recall: 0.984375\n",
      "SVM mean accuracy: 0.984243697479\n",
      "SVM mean F1-Score: 0.985060690943\n",
      "SVM mean precision: 0.988235294118\n",
      "SVM mean recall: 0.985294117647\n",
      "SVM mean accuracy: 0.985119047619\n",
      "SVM mean F1-Score: 0.985890652557\n",
      "SVM mean precision: 0.988888888889\n",
      "SVM mean recall: 0.986111111111\n",
      "SVM mean accuracy: 0.977443609023\n",
      "SVM mean F1-Score: 0.979114452799\n",
      "SVM mean precision: 0.976315789474\n",
      "SVM mean recall: 0.986842105263\n",
      "SVM mean accuracy: 0.984523809524\n",
      "SVM mean F1-Score: 0.982857142857\n",
      "SVM mean precision: 0.9875\n",
      "SVM mean recall: 0.983333333333\n",
      "SVM mean accuracy: 0.984126984127\n",
      "SVM mean F1-Score: 0.980952380952\n",
      "SVM mean precision: 0.984126984127\n",
      "SVM mean recall: 0.984126984127\n",
      "SVM mean accuracy: 0.984848484848\n",
      "SVM mean F1-Score: 0.981818181818\n",
      "SVM mean precision: 0.984848484848\n",
      "SVM mean recall: 0.984848484848\n",
      "SVM mean accuracy: 0.975362318841\n",
      "SVM mean F1-Score: 0.976397515528\n",
      "SVM mean precision: 0.985507246377\n",
      "SVM mean recall: 0.974637681159\n",
      "SVM mean accuracy: 0.976388888889\n",
      "SVM mean F1-Score: 0.977380952381\n",
      "SVM mean precision: 0.986111111111\n",
      "SVM mean recall: 0.975694444444\n",
      "SVM mean accuracy: 0.976\n",
      "SVM mean F1-Score: 0.972952380952\n",
      "SVM mean precision: 0.98\n",
      "SVM mean recall: 0.976666666667\n",
      "SVM mean accuracy: 0.976923076923\n",
      "SVM mean F1-Score: 0.973992673993\n",
      "SVM mean precision: 0.980769230769\n",
      "SVM mean recall: 0.977564102564\n",
      "SVM mean accuracy: 0.974074074074\n",
      "SVM mean F1-Score: 0.94532627866\n",
      "SVM mean precision: 0.953703703704\n",
      "SVM mean recall: 0.944444444444\n",
      "SVM mean accuracy: 0.975\n",
      "SVM mean F1-Score: 0.947278911565\n",
      "SVM mean precision: 0.955357142857\n",
      "SVM mean recall: 0.946428571429\n",
      "SVM mean accuracy: 0.975862068966\n",
      "SVM mean F1-Score: 0.949096880131\n",
      "SVM mean precision: 0.956896551724\n",
      "SVM mean recall: 0.948275862069\n",
      "SVM mean accuracy: 0.976666666667\n",
      "SVM mean F1-Score: 0.950793650794\n",
      "SVM mean precision: 0.958333333333\n",
      "SVM mean recall: 0.95\n",
      "SVM mean accuracy: 0.975806451613\n",
      "SVM mean F1-Score: 0.94623655914\n",
      "SVM mean precision: 0.951612903226\n",
      "SVM mean recall: 0.951612903226\n",
      "SVM mean accuracy: 0.9765625\n",
      "SVM mean F1-Score: 0.947916666667\n",
      "SVM mean precision: 0.953125\n",
      "SVM mean recall: 0.953125\n",
      "SVM mean accuracy: 0.977272727273\n",
      "SVM mean F1-Score: 0.949494949495\n",
      "SVM mean precision: 0.954545454545\n",
      "SVM mean recall: 0.954545454545\n",
      "SVM mean accuracy: 0.982843137255\n",
      "SVM mean F1-Score: 0.960784313725\n",
      "SVM mean precision: 0.955882352941\n",
      "SVM mean recall: 0.970588235294\n",
      "SVM mean accuracy: 0.983333333333\n",
      "SVM mean F1-Score: 0.961904761905\n",
      "SVM mean precision: 0.957142857143\n",
      "SVM mean recall: 0.971428571429\n",
      "SVM mean accuracy: 0.983796296296\n",
      "SVM mean F1-Score: 0.935185185185\n",
      "SVM mean precision: 0.930555555556\n",
      "SVM mean recall: 0.944444444444\n",
      "SVM mean accuracy: 0.984234234234\n",
      "SVM mean F1-Score: 0.936936936937\n",
      "SVM mean precision: 0.932432432432\n",
      "SVM mean recall: 0.945945945946\n",
      "SVM mean accuracy: 0.984649122807\n",
      "SVM mean F1-Score: 0.938596491228\n",
      "SVM mean precision: 0.934210526316\n",
      "SVM mean recall: 0.947368421053\n",
      "SVM mean accuracy: 0.985042735043\n",
      "SVM mean F1-Score: 0.940170940171\n",
      "SVM mean precision: 0.935897435897\n",
      "SVM mean recall: 0.948717948718\n",
      "SVM mean accuracy: 0.985416666667\n",
      "SVM mean F1-Score: 0.941666666667\n",
      "SVM mean precision: 0.9375\n",
      "SVM mean recall: 0.95\n",
      "SVM mean accuracy: 0.983739837398\n",
      "SVM mean F1-Score: 0.943089430894\n",
      "SVM mean precision: 0.939024390244\n",
      "SVM mean recall: 0.951219512195\n",
      "SVM mean accuracy: 0.984126984127\n",
      "SVM mean F1-Score: 0.944444444444\n",
      "SVM mean precision: 0.940476190476\n",
      "SVM mean recall: 0.952380952381\n",
      "SVM mean accuracy: 0.984496124031\n",
      "SVM mean F1-Score: 0.945736434109\n",
      "SVM mean precision: 0.941860465116\n",
      "SVM mean recall: 0.953488372093\n",
      "SVM mean accuracy: 0.984848484848\n",
      "SVM mean F1-Score: 0.94696969697\n",
      "SVM mean precision: 0.943181818182\n",
      "SVM mean recall: 0.954545454545\n",
      "SVM mean accuracy: 0.985185185185\n",
      "SVM mean F1-Score: 0.925925925926\n",
      "SVM mean precision: 0.922222222222\n",
      "SVM mean recall: 0.933333333333\n",
      "SVM mean accuracy: 0.981884057971\n",
      "SVM mean F1-Score: 0.905797101449\n",
      "SVM mean precision: 0.902173913043\n",
      "SVM mean recall: 0.913043478261\n",
      "SVM mean accuracy: 0.982269503546\n",
      "SVM mean F1-Score: 0.90780141844\n",
      "SVM mean precision: 0.904255319149\n",
      "SVM mean recall: 0.914893617021\n",
      "SVM mean accuracy: 0.982638888889\n",
      "SVM mean F1-Score: 0.909722222222\n",
      "SVM mean precision: 0.90625\n",
      "SVM mean recall: 0.916666666667\n",
      "SVM mean accuracy: 0.982993197279\n",
      "SVM mean F1-Score: 0.91156462585\n",
      "SVM mean precision: 0.908163265306\n",
      "SVM mean recall: 0.918367346939\n",
      "SVM mean accuracy: 0.983333333333\n",
      "SVM mean F1-Score: 0.913333333333\n",
      "SVM mean precision: 0.91\n",
      "SVM mean recall: 0.92\n",
      "SVM mean accuracy: 0.983660130719\n",
      "SVM mean F1-Score: 0.915032679739\n",
      "SVM mean precision: 0.911764705882\n",
      "SVM mean recall: 0.921568627451\n",
      "SVM mean accuracy: 0.983974358974\n",
      "SVM mean F1-Score: 0.916666666667\n",
      "SVM mean precision: 0.913461538462\n",
      "SVM mean recall: 0.923076923077\n",
      "SVM mean accuracy: 0.98427672956\n",
      "SVM mean F1-Score: 0.918238993711\n",
      "SVM mean precision: 0.915094339623\n",
      "SVM mean recall: 0.924528301887\n",
      "SVM mean accuracy: 0.984567901235\n",
      "SVM mean F1-Score: 0.901234567901\n",
      "SVM mean precision: 0.898148148148\n",
      "SVM mean recall: 0.907407407407\n",
      "SVM mean accuracy: 0.984848484848\n",
      "SVM mean F1-Score: 0.884848484848\n",
      "SVM mean precision: 0.881818181818\n",
      "SVM mean recall: 0.890909090909\n",
      "SVM mean accuracy: 0.985119047619\n",
      "SVM mean F1-Score: 0.886904761905\n",
      "SVM mean precision: 0.883928571429\n",
      "SVM mean recall: 0.892857142857\n",
      "SVM mean accuracy: 0.985380116959\n",
      "SVM mean F1-Score: 0.87134502924\n",
      "SVM mean precision: 0.868421052632\n",
      "SVM mean recall: 0.877192982456\n",
      "SVM mean accuracy: 0.985632183908\n",
      "SVM mean F1-Score: 0.873563218391\n",
      "SVM mean precision: 0.870689655172\n",
      "SVM mean recall: 0.879310344828\n",
      "SVM mean accuracy: 0.983050847458\n",
      "SVM mean F1-Score: 0.864406779661\n",
      "SVM mean precision: 0.864406779661\n",
      "SVM mean recall: 0.864406779661\n",
      "SVM mean accuracy: 0.983333333333\n",
      "SVM mean F1-Score: 0.866666666667\n",
      "SVM mean precision: 0.866666666667\n",
      "SVM mean recall: 0.866666666667\n",
      "SVM mean accuracy: 0.983606557377\n",
      "SVM mean F1-Score: 0.868852459016\n",
      "SVM mean precision: 0.868852459016\n",
      "SVM mean recall: 0.868852459016\n",
      "SVM mean accuracy: 0.983870967742\n",
      "SVM mean F1-Score: 0.870967741935\n",
      "SVM mean precision: 0.870967741935\n",
      "SVM mean recall: 0.870967741935\n",
      "SVM mean accuracy: 0.984126984127\n",
      "SVM mean F1-Score: 0.873015873016\n",
      "SVM mean precision: 0.873015873016\n",
      "SVM mean recall: 0.873015873016\n",
      "SVM mean accuracy: 0.984375\n",
      "SVM mean F1-Score: 0.875\n",
      "SVM mean precision: 0.875\n",
      "SVM mean recall: 0.875\n",
      "SVM mean accuracy: 0.984615384615\n",
      "SVM mean F1-Score: 0.876923076923\n",
      "SVM mean precision: 0.876923076923\n",
      "SVM mean recall: 0.876923076923\n",
      "SVM mean accuracy: 0.984848484848\n",
      "SVM mean F1-Score: 0.878787878788\n",
      "SVM mean precision: 0.878787878788\n",
      "SVM mean recall: 0.878787878788\n",
      "SVM mean accuracy: 0.985074626866\n",
      "SVM mean F1-Score: 0.865671641791\n",
      "SVM mean precision: 0.865671641791\n",
      "SVM mean recall: 0.865671641791\n",
      "SVM mean accuracy: 0.985294117647\n",
      "SVM mean F1-Score: 0.852941176471\n",
      "SVM mean precision: 0.852941176471\n",
      "SVM mean recall: 0.852941176471\n",
      "SVM mean accuracy: 0.985507246377\n",
      "SVM mean F1-Score: 0.855072463768\n",
      "SVM mean precision: 0.855072463768\n",
      "SVM mean recall: 0.855072463768\n",
      "SVM mean accuracy: 0.985714285714\n",
      "SVM mean F1-Score: 0.857142857143\n",
      "SVM mean precision: 0.857142857143\n",
      "SVM mean recall: 0.857142857143\n",
      "SVM mean accuracy: 0.985915492958\n",
      "SVM mean F1-Score: 0.845070422535\n",
      "SVM mean precision: 0.845070422535\n",
      "SVM mean recall: 0.845070422535\n",
      "SVM mean accuracy: 0.979166666667\n",
      "SVM mean F1-Score: 0.833333333333\n",
      "SVM mean precision: 0.833333333333\n",
      "SVM mean recall: 0.833333333333\n",
      "SVM mean accuracy: 0.979452054795\n",
      "SVM mean F1-Score: 0.835616438356\n",
      "SVM mean precision: 0.835616438356\n",
      "SVM mean recall: 0.835616438356\n",
      "SVM mean accuracy: 0.97972972973\n",
      "SVM mean F1-Score: 0.824324324324\n",
      "SVM mean precision: 0.824324324324\n",
      "SVM mean recall: 0.824324324324\n",
      "SVM mean accuracy: 0.98\n",
      "SVM mean F1-Score: 0.826666666667\n",
      "SVM mean precision: 0.826666666667\n",
      "SVM mean recall: 0.826666666667\n",
      "SVM mean accuracy: 0.980263157895\n",
      "SVM mean F1-Score: 0.815789473684\n",
      "SVM mean precision: 0.815789473684\n",
      "SVM mean recall: 0.815789473684\n",
      "SVM mean accuracy: 0.980519480519\n",
      "SVM mean F1-Score: 0.818181818182\n",
      "SVM mean precision: 0.818181818182\n",
      "SVM mean recall: 0.818181818182\n",
      "SVM mean accuracy: 0.980769230769\n",
      "SVM mean F1-Score: 0.820512820513\n",
      "SVM mean precision: 0.820512820513\n",
      "SVM mean recall: 0.820512820513\n",
      "SVM mean accuracy: 0.981012658228\n",
      "SVM mean F1-Score: 0.810126582278\n",
      "SVM mean precision: 0.810126582278\n",
      "SVM mean recall: 0.810126582278\n",
      "SVM mean accuracy: 0.98125\n",
      "SVM mean F1-Score: 0.8\n",
      "SVM mean precision: 0.8\n",
      "SVM mean recall: 0.8\n",
      "SVM mean accuracy: 0.981481481481\n",
      "SVM mean F1-Score: 0.802469135802\n",
      "SVM mean precision: 0.802469135802\n",
      "SVM mean recall: 0.802469135802\n",
      "SVM mean accuracy: 0.981707317073\n",
      "SVM mean F1-Score: 0.80487804878\n",
      "SVM mean precision: 0.80487804878\n",
      "SVM mean recall: 0.80487804878\n",
      "SVM mean accuracy: 0.981927710843\n",
      "SVM mean F1-Score: 0.795180722892\n",
      "SVM mean precision: 0.795180722892\n",
      "SVM mean recall: 0.795180722892\n",
      "SVM mean accuracy: 0.982142857143\n",
      "SVM mean F1-Score: 0.785714285714\n",
      "SVM mean precision: 0.785714285714\n",
      "SVM mean recall: 0.785714285714\n",
      "SVM mean accuracy: 0.982352941176\n",
      "SVM mean F1-Score: 0.776470588235\n",
      "SVM mean precision: 0.776470588235\n",
      "SVM mean recall: 0.776470588235\n",
      "SVM mean accuracy: 0.982558139535\n",
      "SVM mean F1-Score: 0.779069767442\n",
      "SVM mean precision: 0.779069767442\n",
      "SVM mean recall: 0.779069767442\n",
      "SVM mean accuracy: 0.98275862069\n",
      "SVM mean F1-Score: 0.781609195402\n",
      "SVM mean precision: 0.781609195402\n",
      "SVM mean recall: 0.781609195402\n",
      "SVM mean accuracy: 0.982954545455\n",
      "SVM mean F1-Score: 0.784090909091\n",
      "SVM mean precision: 0.784090909091\n",
      "SVM mean recall: 0.784090909091\n",
      "SVM mean accuracy: 0.983146067416\n",
      "SVM mean F1-Score: 0.775280898876\n",
      "SVM mean precision: 0.775280898876\n",
      "SVM mean recall: 0.775280898876\n",
      "SVM mean accuracy: 0.983333333333\n",
      "SVM mean F1-Score: 0.777777777778\n",
      "SVM mean precision: 0.777777777778\n",
      "SVM mean recall: 0.777777777778\n",
      "SVM mean accuracy: 0.983516483516\n",
      "SVM mean F1-Score: 0.78021978022\n",
      "SVM mean precision: 0.78021978022\n",
      "SVM mean recall: 0.78021978022\n",
      "SVM mean accuracy: 0.983695652174\n",
      "SVM mean F1-Score: 0.782608695652\n",
      "SVM mean precision: 0.782608695652\n",
      "SVM mean recall: 0.782608695652\n",
      "SVM mean accuracy: 0.983870967742\n",
      "SVM mean F1-Score: 0.774193548387\n",
      "SVM mean precision: 0.774193548387\n",
      "SVM mean recall: 0.774193548387\n",
      "SVM mean accuracy: 0.984042553191\n",
      "SVM mean F1-Score: 0.765957446809\n",
      "SVM mean precision: 0.765957446809\n",
      "SVM mean recall: 0.765957446809\n",
      "SVM mean accuracy: 0.984210526316\n",
      "SVM mean F1-Score: 0.757894736842\n",
      "SVM mean precision: 0.757894736842\n",
      "SVM mean recall: 0.757894736842\n",
      "SVM mean accuracy: 0.984375\n",
      "SVM mean F1-Score: 0.760416666667\n",
      "SVM mean precision: 0.760416666667\n",
      "SVM mean recall: 0.760416666667\n",
      "SVM mean accuracy: 0.984536082474\n",
      "SVM mean F1-Score: 0.752577319588\n",
      "SVM mean precision: 0.752577319588\n",
      "SVM mean recall: 0.752577319588\n",
      "SVM mean accuracy: 0.984693877551\n",
      "SVM mean F1-Score: 0.755102040816\n",
      "SVM mean precision: 0.755102040816\n",
      "SVM mean recall: 0.755102040816\n",
      "SVM mean accuracy: 0.984848484848\n",
      "SVM mean F1-Score: 0.747474747475\n",
      "SVM mean precision: 0.747474747475\n",
      "SVM mean recall: 0.747474747475\n",
      "SVM mean accuracy: 0.985\n",
      "SVM mean F1-Score: 0.75\n",
      "SVM mean precision: 0.75\n",
      "SVM mean recall: 0.75\n",
      "SVM mean accuracy: 0.985148514851\n",
      "SVM mean F1-Score: 0.742574257426\n",
      "SVM mean precision: 0.742574257426\n",
      "SVM mean recall: 0.742574257426\n",
      "SVM mean accuracy: 0.985294117647\n",
      "SVM mean F1-Score: 0.745098039216\n",
      "SVM mean precision: 0.745098039216\n",
      "SVM mean recall: 0.745098039216\n",
      "SVM mean accuracy: 0.985436893204\n",
      "SVM mean F1-Score: 0.747572815534\n",
      "SVM mean precision: 0.747572815534\n",
      "SVM mean recall: 0.747572815534\n",
      "SVM mean accuracy: 0.985576923077\n",
      "SVM mean F1-Score: 0.740384615385\n",
      "SVM mean precision: 0.740384615385\n",
      "SVM mean recall: 0.740384615385\n",
      "SVM mean accuracy: 0.985714285714\n",
      "SVM mean F1-Score: 0.742857142857\n",
      "SVM mean precision: 0.742857142857\n",
      "SVM mean recall: 0.742857142857\n",
      "SVM mean accuracy: 0.985849056604\n",
      "SVM mean F1-Score: 0.745283018868\n",
      "SVM mean precision: 0.745283018868\n",
      "SVM mean recall: 0.745283018868\n",
      "SVM mean accuracy: 0.985981308411\n",
      "SVM mean F1-Score: 0.747663551402\n",
      "SVM mean precision: 0.747663551402\n",
      "SVM mean recall: 0.747663551402\n",
      "SVM mean accuracy: 0.986111111111\n",
      "SVM mean F1-Score: 0.75\n",
      "SVM mean precision: 0.75\n",
      "SVM mean recall: 0.75\n",
      "SVM mean accuracy: 0.98623853211\n",
      "SVM mean F1-Score: 0.743119266055\n",
      "SVM mean precision: 0.743119266055\n",
      "SVM mean recall: 0.743119266055\n",
      "SVM mean accuracy: 0.981818181818\n",
      "SVM mean F1-Score: 0.736363636364\n",
      "SVM mean precision: 0.736363636364\n",
      "SVM mean recall: 0.736363636364\n",
      "SVM mean accuracy: 0.981981981982\n",
      "SVM mean F1-Score: 0.72972972973\n",
      "SVM mean precision: 0.72972972973\n",
      "SVM mean recall: 0.72972972973\n",
      "SVM mean accuracy: 0.982142857143\n",
      "SVM mean F1-Score: 0.732142857143\n",
      "SVM mean precision: 0.732142857143\n",
      "SVM mean recall: 0.732142857143\n",
      "SVM mean accuracy: 0.982300884956\n",
      "SVM mean F1-Score: 0.725663716814\n",
      "SVM mean precision: 0.725663716814\n",
      "SVM mean recall: 0.725663716814\n",
      "SVM mean accuracy: 0.982456140351\n",
      "SVM mean F1-Score: 0.719298245614\n",
      "SVM mean precision: 0.719298245614\n",
      "SVM mean recall: 0.719298245614\n",
      "SVM mean accuracy: 0.982608695652\n",
      "SVM mean F1-Score: 0.721739130435\n",
      "SVM mean precision: 0.721739130435\n",
      "SVM mean recall: 0.721739130435\n",
      "SVM mean accuracy: 0.98275862069\n",
      "SVM mean F1-Score: 0.724137931034\n",
      "SVM mean precision: 0.724137931034\n",
      "SVM mean recall: 0.724137931034\n",
      "SVM mean accuracy: 0.982905982906\n",
      "SVM mean F1-Score: 0.726495726496\n",
      "SVM mean precision: 0.726495726496\n",
      "SVM mean recall: 0.726495726496\n",
      "SVM mean accuracy: 0.983050847458\n",
      "SVM mean F1-Score: 0.728813559322\n",
      "SVM mean precision: 0.728813559322\n",
      "SVM mean recall: 0.728813559322\n",
      "SVM mean accuracy: 0.983193277311\n",
      "SVM mean F1-Score: 0.72268907563\n",
      "SVM mean precision: 0.72268907563\n",
      "SVM mean recall: 0.72268907563\n"
     ]
    }
   ],
   "source": [
    "# Using k-fold cross validations\n",
    "accN = np.zeros((n_folds,))\n",
    "f1N = np.zeros((n_folds,))\n",
    "precisionN = np.zeros((n_folds,))\n",
    "recallN = np.zeros((n_folds,))\n",
    "j=0\n",
    "for n_folds in range(2,120): ## IF N_FOLDS is the size of the set, it is the same as LOO below\n",
    "    kf=cross_validation.KFold(n=y.shape[0], n_folds=n_folds, shuffle=False, random_state=0)\n",
    "    acc = np.zeros((n_folds,))\n",
    "    f1 = np.zeros((n_folds,))\n",
    "    precision = np.zeros((n_folds,))\n",
    "    recall = np.zeros((n_folds,))\n",
    "    i = 0\n",
    "    X = X\n",
    "    y = y\n",
    "    yhat = y.copy()\n",
    "    for train_index, test_index in kf:\n",
    "     \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "   \n",
    "    #dt = RandomForestClassifier(max_depth = max_depth, min_samples_split=min_samples_split, n_estimators=n_estimators, random_state = random_state,class_weight=class_weight)\n",
    "#    svc = SVC( C = C, gamma = gamma, shrinking = shrinking, probability = probability, verbose = verbose,class_weight='balanced')\n",
    "        svc = svm.SVC(C=C,kernel='rbf',class_weight='balanced')        \n",
    "        svc.fit(X_train,y_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        yhat[test_index] = svc.predict(X_test)\n",
    "        acc[i] = metrics.accuracy_score(yhat[test_index], y_test)\n",
    "        f1[i]  = metrics.f1_score(yhat[test_index], y_test)\n",
    "        precision[i] = metrics.precision_score(yhat[test_index], y_test)\n",
    "        recall[i] = metrics.recall_score(yhat[test_index], y_test)\n",
    "        i=i+1\n",
    "\n",
    "    print ('SVM mean accuracy: '+ str(np.mean(acc)))\n",
    "    print ('SVM mean F1-Score: '+ str(np.mean(f1)))\n",
    "    print ('SVM mean precision: '+ str(np.mean(precision)))\n",
    "    print ('SVM mean recall: '+ str(np.mean(recall)))\n",
    "    \n",
    "    accN[j]=np.mean(acc)\n",
    "    f1N[j]=np.mean(f1)\n",
    "    precisionN[j]=np.mean(precision)\n",
    "    recall[j]=np.mean(recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD8CAYAAADUv3dIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA1M9ePggwd36AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b128750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4)\n",
    "scaler=StandardScaler()\n",
    "X_l = scaler.fit_transform(X) ## we need this only for the axis definition\n",
    "\n",
    "## plot grid\n",
    "\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "x_min, x_max = X_l[:, 0].min() - .5, X_l[:, 0].max() + .5\n",
    "y_min, y_max = X_l[:, 1].min() - .5, X_l[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n",
    "\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#008000'])\n",
    "cm_dark = ListedColormap(['#8A2BE2','#D2691E'])\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "# Plot the training points\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)\n",
    "    # and testing points\n",
    "    \n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.2)\n",
    "ax.set_xlim(xx.min(), xx.max())\n",
    "ax.set_ylim(yy.min(), yy.max())\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "\n",
    "ax.set_title('SVM')\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "    #dt = RandomForestClassifier(max_depth = max_depth, min_samples_split=min_samples_split, n_estimators=n_estimators, random_state = random_state,class_weight=class_weight)\n",
    "#    svc = SVC( C = C, gamma = gamma, shrinking = shrinking, probability = probability, verbose = verbose,class_weight='balanced')\n",
    "svc = svm.SVC(C=1,kernel='rbf',class_weight='balanced')        \n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "score = svc.score(X_test, y_test)\n",
    "\n",
    "y_predict=svc.predict(X_test)\n",
    "\n",
    "        # Plot also the training points\n",
    "#ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)\n",
    "        # and testing points\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_predict, cmap=cm_dark,marker='x')\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,alpha=0.2)\n",
    "\n",
    "\n",
    "ax.set_xlim(xx.min(), xx.max())\n",
    "ax.set_ylim(yy.min(), yy.max())\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "ax.set_title(score)\n",
    "ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "                size=15, horizontalalignment='right')\n",
    "\n",
    "plt.savefig('SVM.png' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0\n",
      "  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print y_test-y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PRC=0.7\n",
    "X_train, y_train, X_test, y_test = randomization_train_2_twoSet(X,y,PRC=PRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest ..\n"
     ]
    }
   ],
   "source": [
    "print ('Training Random Forest ..')\n",
    "n_estimators = 51\n",
    "max_depth = 12\n",
    "min_samples_split = 2\n",
    "random_state = 1\n",
    "max_features = 'auto'\n",
    "verbose = 1\n",
    "n_jobs = 1\n",
    "\n",
    "\n",
    "\n",
    "#class_weight = {0:w_1,1:w_0}\n",
    "class_weight = 'balanced'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Random forest training score ', 1.0)\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=12, max_features='auto',\n",
      "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=51, n_jobs=1,\n",
      "            oob_score=False, random_state=1, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#normalization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "forest = RandomForestClassifier(max_depth = max_depth, min_samples_split=min_samples_split, n_estimators=n_estimators, random_state = random_state,class_weight=class_weight)\n",
    "##forest = RandomForestClassifier(n_estimators=n_estimators,max_depth = max_depth,min_samples_split=min_samples_split,class_weight=class_weight)\n",
    "my_forest = forest.fit(X_train,y_train)\n",
    "print ('Random forest training score ',my_forest.score(X_train,y_train))\n",
    "print my_forest\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest mean accuracy: 0.947252747253\n",
      "Random Forest mean F1-Score: 0.958817440019\n",
      "Random Forest mean precision: 0.980555555556\n",
      "Random Forest mean recall: 0.944318181818\n"
     ]
    }
   ],
   "source": [
    "## Using k-fold cross validation to measure performance\n",
    "n_folds = 10 ## AS ABOVE THE ACCURACY DECREASES WHEN INCREASING n_folds\n",
    "kf=cross_validation.KFold(n=y.shape[0], n_folds=n_folds, shuffle=False, random_state=0)\n",
    "\n",
    "acc = np.zeros((n_folds,))\n",
    "precision = np.zeros((n_folds,))\n",
    "recall = np.zeros((n_folds,))\n",
    "#thresholds = np.zeros((n_folds,))\n",
    "f1 = np.zeros((n_folds,))\n",
    "i = 0\n",
    "X = X\n",
    "y = y\n",
    "yhat = y.copy()\n",
    "for train_index, test_index in kf:\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    dt = RandomForestClassifier(max_depth = max_depth, min_samples_split=min_samples_split, n_estimators=n_estimators, random_state = random_state,class_weight=class_weight)\n",
    "    \n",
    "    dt.fit(X_train,y_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    yhat[test_index] = dt.predict(X_test)\n",
    "    acc[i] = metrics.accuracy_score(yhat[test_index], y_test)\n",
    "    precision[i] = metrics.precision_score(yhat[test_index], y_test)\n",
    "    recall[i] = metrics.recall_score(yhat[test_index], y_test)\n",
    "    f1[i]  = metrics.f1_score(yhat[test_index], y_test)\n",
    "    i=i+1\n",
    "\n",
    "print ('Random Forest mean accuracy: '+ str(np.mean(acc)))\n",
    "print ('Random Forest mean F1-Score: '+ str(np.mean(f1)))\n",
    "print ('Random Forest mean precision: '+ str(np.mean(precision)))\n",
    "print ('Random Forest mean recall: '+ str(np.mean(recall)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM mean accuracy: 0.962121212121\n",
      "SVM mean F1-Score: 0.689393939394\n",
      "SVM mean precision: 0.689393939394\n",
      "SVM mean recall: 0.689393939394\n"
     ]
    }
   ],
   "source": [
    "n_loo=y.size\n",
    "loo=cross_validation.LeaveOneOut(n_loo)\n",
    "\n",
    "acc = np.zeros((n_loo,))\n",
    "f1 = np.zeros((n_loo,))\n",
    "precision = np.zeros((n_loo,))\n",
    "recall = np.zeros((n_loo,))\n",
    "i = 0\n",
    "X = X\n",
    "y = y\n",
    "yhat = y.copy()\n",
    "\n",
    "for train_index, test_index in loo:\n",
    "\n",
    "      \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    \n",
    "  \n",
    "    dt = RandomForestClassifier(max_depth = max_depth, min_samples_split=min_samples_split, n_estimators=n_estimators, random_state = random_state,class_weight=class_weight)\n",
    "#    svc = SVC( C = C, gamma = gamma, shrinking = shrinking, probability = probability, verbose = verbose,class_weight='balanced')\n",
    "# svc = svm.SVC(C=1,kernel='rbf',class_weight='balanced')        \n",
    "    dt.fit(X_train,y_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    yhat[test_index] = dt.predict(X_test)\n",
    "\n",
    "    acc[i] = metrics.accuracy_score(yhat[test_index], y_test)\n",
    "    f1[i]  = metrics.f1_score(yhat[test_index], y_test)\n",
    "    precision[i] = metrics.precision_score(yhat[test_index], y_test)\n",
    "    recall[i] = metrics.recall_score(yhat[test_index], y_test)\n",
    "    i=i+1\n",
    "\n",
    "print ('SVM mean accuracy: '+ str(np.mean(acc)))\n",
    "print ('SVM mean F1-Score: '+ str(np.mean(f1)))\n",
    "print ('SVM mean precision: '+ str(np.mean(precision)))\n",
    "print ('SVM mean recall: '+ str(np.mean(recall)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD8CAYAAADUv3dIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXUgkXUEQhC4kkq4gCEIX+v+EDN6Xda1nbwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b78a390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5)\n",
    "\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_l = scaler.fit_transform(X) ## we need this only for the axis definition\n",
    "\n",
    "## plot grid\n",
    "h = .02  # step size in the mesh\n",
    "x_min, x_max = X_l[:, 0].min() - .5, X_l[:, 0].max() + .5\n",
    "y_min, y_max = X_l[:, 1].min() - .5, X_l[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n",
    "\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#008000'])\n",
    "cm_dark = ListedColormap(['#8A2BE2','#D2691E'])\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "# Plot the training points\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)\n",
    "    # and testing points\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.2)\n",
    "ax.set_xlim(xx.min(), xx.max())\n",
    "ax.set_ylim(yy.min(), yy.max())\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "\n",
    "ax.set_title('RandomForest')\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "\n",
    "\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "dt = RandomForestClassifier(max_depth = max_depth, min_samples_split=min_samples_split, n_estimators=n_estimators, random_state = random_state,class_weight=class_weight)\n",
    "    \n",
    "dt.fit(X_train,y_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "score = svc.score(X_test, y_test)\n",
    "\n",
    "y_predict=dt.predict(X_test)\n",
    "\n",
    "        # Plot also the training points\n",
    "#ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)\n",
    "        # and testing points\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_predict, cmap=cm_dark,marker='x')\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,alpha=0.2)\n",
    "\n",
    "\n",
    "\n",
    "ax.set_xlim(xx.min(), xx.max())\n",
    "ax.set_ylim(yy.min(), yy.max())\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "ax.set_title(score)\n",
    "\n",
    "plt.savefig('RandomForest.png' )\n",
    "#plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regresion..\n"
     ]
    }
   ],
   "source": [
    "print ('Logistic Regresion..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regresion accuracy: 0.954545454545\n",
      "Logistic regression F1-Score: 0.666666666667\n",
      "Logistic regression precision: 0.666666666667\n",
      "Logistic regression recall: 0.666666666667\n"
     ]
    }
   ],
   "source": [
    "n_folds = n_loo\n",
    "kf=cross_validation.KFold(n=y.shape[0], n_folds=n_folds, shuffle=False, random_state=0)\n",
    "\n",
    "acc = np.zeros((n_folds,))\n",
    "f1 = np.zeros((n_folds,))\n",
    "precision = np.zeros((n_folds,))\n",
    "recall = np.zeros((n_folds,))\n",
    "i = 0\n",
    "X = X\n",
    "y = y\n",
    "yhat = y.copy()\n",
    "for train_index, test_index in kf:\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    dt = LogisticRegression()\n",
    "    \n",
    "    dt.fit(X_train,y_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    yhat[test_index] = dt.predict(X_test)\n",
    "    acc[i] = metrics.accuracy_score(yhat[test_index], y_test)\n",
    "    f1[i]  = metrics.f1_score(yhat[test_index], y_test)\n",
    "    precision[i] = metrics.precision_score(yhat[test_index], y_test)\n",
    "    recall[i] = metrics.recall_score(yhat[test_index], y_test)\n",
    "\n",
    "    i=i+1\n",
    "\n",
    "print ('Logistic regresion accuracy: '+ str(np.mean(acc)))\n",
    "print ('Logistic regression F1-Score: '+ str(np.mean(f1)))\n",
    "print ('Logistic regression precision: '+ str(np.mean(precision)))\n",
    "print ('Logistic regression recall: '+ str(np.mean(recall)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mirta/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/mirta/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM mean accuracy: 0.628787878788\n",
      "SVM mean F1-Score: 0.606060606061\n",
      "SVM mean precision: 0.606060606061\n",
      "SVM mean recall: 0.606060606061\n"
     ]
    }
   ],
   "source": [
    "n_loo=y.size\n",
    "loo=cross_validation.LeaveOneOut(n_loo)\n",
    "\n",
    "acc = np.zeros((n_loo,))\n",
    "f1 = np.zeros((n_loo,))\n",
    "precision = np.zeros((n_loo,))\n",
    "recall = np.zeros((n_loo,))\n",
    "i = 0\n",
    "X = X\n",
    "y = y\n",
    "yhat = y.copy()\n",
    "for train_index, test_index in loo:\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    #dt = RandomForestClassifier(max_depth = max_depth, min_samples_split=min_samples_split, n_estimators=n_estimators, random_state = random_state,class_weight=class_weight)\n",
    "#    svc = SVC( C = C, gamma = gamma, shrinking = shrinking, probability = probability, verbose = verbose,class_weight='balanced')\n",
    "    dt = LogisticRegression()\n",
    "    \n",
    "    dt.fit(X_train,y_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    yhat[test_index] = svc.predict(X_test)\n",
    "    acc[i] = metrics.accuracy_score(yhat[test_index], y_test)\n",
    "    f1[i]  = metrics.f1_score(yhat[test_index], y_test)\n",
    "    precision[i] = metrics.precision_score(yhat[test_index], y_test)\n",
    "    recall[i] = metrics.recall_score(yhat[test_index], y_test)\n",
    "    i=i+1\n",
    "\n",
    "print ('SVM mean accuracy: '+ str(np.mean(acc)))\n",
    "print ('SVM mean F1-Score: '+ str(np.mean(f1)))\n",
    "print ('SVM mean precision: '+ str(np.mean(precision)))\n",
    "print ('SVM mean recall: '+ str(np.mean(recall)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.7)\n",
    "\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_l = scaler.fit_transform(X) ## we need this only for the axis definition\n",
    "## plot grid\n",
    "h = .02  # step size in the mesh\n",
    "x_min, x_max = X_l[:, 0].min() - .5, X_l[:, 0].max() + .5\n",
    "y_min, y_max = X_l[:, 1].min() - .5, X_l[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n",
    "\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#008000'])\n",
    "cm_dark = ListedColormap(['#8A2BE2','#D2691E'])\n",
    "\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "# Plot the training points\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)\n",
    "    # and testing points\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.2)\n",
    "ax.set_xlim(xx.min(), xx.max())\n",
    "ax.set_ylim(yy.min(), yy.max())\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "ax.set_title('Logistic Regression')\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "\n",
    "dt = LogisticRegression()\n",
    "    \n",
    "dt.fit(X_train,y_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "score = svc.score(X_test, y_test)\n",
    "\n",
    "y_predict=dt.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Plot also the training points\n",
    "#ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)\n",
    "        # and testing points\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_predict, cmap=cm_dark,marker='x')\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,alpha=0.2,marker='o')\n",
    "\n",
    "\n",
    "\n",
    "ax.set_xlim(xx.min(), xx.max())\n",
    "ax.set_ylim(yy.min(), yy.max())\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "ax.set_title(score)\n",
    "\n",
    "#plt.figure()\n",
    "\n",
    "plt.savefig('LogisticRegression.png' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1.Read DAta\n",
    "path_data = '/Users/mirta/BIGDATA/PROJECT/ADHD_Project-master/SupervisedLearning/data_for_learning/'\n",
    "train = pd.read_csv(path_data+'SupervisedLearningDataSet_Lunes11.csv')\n",
    "\n",
    "train = train[train.experiment == 'B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9372"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn import cross_validation\n",
    "#import pylab as pl\n",
    "import numpy as np\n",
    "\n",
    "X_train, X_test, y_train, y_test =   cross_validation.train_test_split(X,y, test_size=0.10, random_state=111)\n",
    "pca = PCA(n_components=2).fit(X_train)\n",
    "pca_2d = pca.transform(X_train)\n",
    "svmClassifier_2d = svm.SVC(random_state=111).fit(pca_2d, y_train)\n",
    "\n",
    "\n",
    "for i in range(0, pca_2d.shape[0]):\n",
    "    if y_train[i] == 0:\n",
    "        plt.scatter(pca_2d[i,0],pca_2d[i,1],c='r',    s=50,marker='+')\n",
    "    elif y_train[i] == 1:\n",
    "        plt.scatter(pca_2d[i,0],pca_2d[i,1],c='g',    s=50,marker='o')\n",
    "  \n",
    " #   pl.legend([c1, c2], ['Healthy', 'Sick'])\n",
    "x_min, x_max = pca_2d[:, 0].min() - 1,   pca_2d[:,0].max() + 1\n",
    "y_min, y_max = pca_2d[:, 1].min() - 1,   pca_2d[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, .01),   np.arange(y_min, y_max, .01))\n",
    "Z = svmClassifier_2d.predict(np.c_[xx.ravel(),  yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contour(xx, yy, Z)\n",
    "plt.title('Support Vector Machine Decision Surface')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.77958205,  0.22041795])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.feature_importances_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
